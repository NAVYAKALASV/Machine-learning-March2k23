{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2GfsHawdo6T"
   },
   "source": [
    "# 20BCE1858 S.V.NAVYA KALA\n",
    "# ML LAB-5\n",
    "# DEEP NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pcu8QGukdo6Z"
   },
   "source": [
    "A sneak peek in the Keras Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "no1z01DtecsC"
   },
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m-Z5xgoueeDa"
   },
   "outputs": [],
   "source": [
    "# Getting the data ready\n",
    "# Generate train dummy data for 1000 Students and dummy test for 500\n",
    "#Columns :Age, Hours of Study & Avg Previous test scores\n",
    "np.random.seed(2018)\n",
    "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(2, size=(1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wjhagy9PeeM6",
    "outputId": "42d298b6-078a-40a4-b71d-886f575869ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88234931, 0.10432774, 0.90700933],\n",
       "       [0.3063989 , 0.44640887, 0.58998539],\n",
       "       [0.8371111 , 0.69780061, 0.80280284],\n",
       "       ...,\n",
       "       [0.76474832, 0.12224649, 0.06019634],\n",
       "       [0.21847107, 0.57064847, 0.27701246],\n",
       "       [0.97785211, 0.81210972, 0.34780075]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmocBhvleeUB",
    "outputId": "41db2225-dc4f-4925-a281-904a33404809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35981783, 0.64707122, 0.16858627],\n",
       "       [0.95089881, 0.24401454, 0.39478811],\n",
       "       [0.99185888, 0.01995682, 0.19105642],\n",
       "       ...,\n",
       "       [0.03335012, 0.35559007, 0.5386409 ],\n",
       "       [0.3804594 , 0.11970055, 0.08783101],\n",
       "       [0.83887832, 0.26936355, 0.90847875]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vTveQsSXeeW5"
   },
   "outputs": [],
   "source": [
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dQeCXefeeZZ",
    "outputId": "e562fc7c-a113-4e04-e6d9-9a3adf8a0e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcEFnRqZeecw",
    "outputId": "9934f132-500f-431c-a463-514e795a0f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 2s 12ms/step - loss: 0.7034 - accuracy: 0.4910\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.4950\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.4970\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.5040\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5120\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5110\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.5180\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.5340\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5350\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2604854c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Do-TqfJigND0",
    "outputId": "712d6850-3992-4bb4-d2c7-9403dd565507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTnDMknAgUpX",
    "outputId": "2ad85324-130e-4551-d06d-4774d9dbd4dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49133608],\n",
       "       [0.5055196 ],\n",
       "       [0.49621204],\n",
       "       [0.49903908],\n",
       "       [0.49659538],\n",
       "       [0.47684285],\n",
       "       [0.49990454],\n",
       "       [0.48626286],\n",
       "       [0.4977088 ],\n",
       "       [0.48198596],\n",
       "       [0.49597302],\n",
       "       [0.524187  ],\n",
       "       [0.5270693 ],\n",
       "       [0.51378715],\n",
       "       [0.48441592],\n",
       "       [0.5014784 ],\n",
       "       [0.5193018 ],\n",
       "       [0.49804085],\n",
       "       [0.50814354],\n",
       "       [0.5172637 ],\n",
       "       [0.4900891 ],\n",
       "       [0.49432433],\n",
       "       [0.49305794],\n",
       "       [0.4942884 ],\n",
       "       [0.49617967],\n",
       "       [0.4930838 ],\n",
       "       [0.49859244],\n",
       "       [0.4841309 ],\n",
       "       [0.52610433],\n",
       "       [0.51075697],\n",
       "       [0.49692613],\n",
       "       [0.49639487],\n",
       "       [0.48891538],\n",
       "       [0.5043083 ],\n",
       "       [0.49984902],\n",
       "       [0.49406874],\n",
       "       [0.5247791 ],\n",
       "       [0.5089512 ],\n",
       "       [0.490144  ],\n",
       "       [0.5056448 ],\n",
       "       [0.5346702 ],\n",
       "       [0.529458  ],\n",
       "       [0.5401696 ],\n",
       "       [0.506177  ],\n",
       "       [0.51403904],\n",
       "       [0.4843001 ],\n",
       "       [0.49794182],\n",
       "       [0.49105117],\n",
       "       [0.49608898],\n",
       "       [0.50533766],\n",
       "       [0.49538732],\n",
       "       [0.49356946],\n",
       "       [0.4972116 ],\n",
       "       [0.4884411 ],\n",
       "       [0.48380926],\n",
       "       [0.5380633 ],\n",
       "       [0.49682504],\n",
       "       [0.51102626],\n",
       "       [0.48796326],\n",
       "       [0.4930521 ],\n",
       "       [0.49759915],\n",
       "       [0.51944494],\n",
       "       [0.4982724 ],\n",
       "       [0.4900397 ],\n",
       "       [0.49259597],\n",
       "       [0.48951796],\n",
       "       [0.49898207],\n",
       "       [0.49862996],\n",
       "       [0.5021383 ],\n",
       "       [0.49022967],\n",
       "       [0.48432887],\n",
       "       [0.50159395],\n",
       "       [0.49740255],\n",
       "       [0.49919325],\n",
       "       [0.4992998 ],\n",
       "       [0.51128286],\n",
       "       [0.52090037],\n",
       "       [0.49367377],\n",
       "       [0.50804514],\n",
       "       [0.4877374 ],\n",
       "       [0.48736414],\n",
       "       [0.49546522],\n",
       "       [0.523674  ],\n",
       "       [0.492138  ],\n",
       "       [0.49094912],\n",
       "       [0.49551326],\n",
       "       [0.52848816],\n",
       "       [0.51146   ],\n",
       "       [0.47586486],\n",
       "       [0.4880854 ],\n",
       "       [0.49421442],\n",
       "       [0.49087396],\n",
       "       [0.49922818],\n",
       "       [0.5199722 ],\n",
       "       [0.5122612 ],\n",
       "       [0.490137  ],\n",
       "       [0.4930697 ],\n",
       "       [0.47772467],\n",
       "       [0.532442  ],\n",
       "       [0.5345531 ],\n",
       "       [0.49449253],\n",
       "       [0.4967575 ],\n",
       "       [0.522401  ],\n",
       "       [0.52505356],\n",
       "       [0.5133364 ],\n",
       "       [0.4826567 ],\n",
       "       [0.5169596 ],\n",
       "       [0.5161067 ],\n",
       "       [0.5091615 ],\n",
       "       [0.49312735],\n",
       "       [0.4857145 ],\n",
       "       [0.49823546],\n",
       "       [0.49477947],\n",
       "       [0.49115303],\n",
       "       [0.48630208],\n",
       "       [0.48700064],\n",
       "       [0.52053696],\n",
       "       [0.5289203 ],\n",
       "       [0.48345593],\n",
       "       [0.47711408],\n",
       "       [0.5359483 ],\n",
       "       [0.48964974],\n",
       "       [0.5049818 ],\n",
       "       [0.48145813],\n",
       "       [0.5286523 ],\n",
       "       [0.497528  ],\n",
       "       [0.5123912 ],\n",
       "       [0.48538762],\n",
       "       [0.48243424],\n",
       "       [0.500531  ],\n",
       "       [0.4892127 ],\n",
       "       [0.4979868 ],\n",
       "       [0.5041899 ],\n",
       "       [0.5116443 ],\n",
       "       [0.5061992 ],\n",
       "       [0.49716508],\n",
       "       [0.47586486],\n",
       "       [0.51317936],\n",
       "       [0.53771484],\n",
       "       [0.50310206],\n",
       "       [0.4976433 ],\n",
       "       [0.5221015 ],\n",
       "       [0.49606168],\n",
       "       [0.48607975],\n",
       "       [0.50465167],\n",
       "       [0.5042572 ],\n",
       "       [0.48072898],\n",
       "       [0.518556  ],\n",
       "       [0.4906041 ],\n",
       "       [0.5033341 ],\n",
       "       [0.48307675],\n",
       "       [0.488634  ],\n",
       "       [0.47586486],\n",
       "       [0.4907425 ],\n",
       "       [0.48226085],\n",
       "       [0.49773175],\n",
       "       [0.49036172],\n",
       "       [0.5048512 ],\n",
       "       [0.4865703 ],\n",
       "       [0.48054928],\n",
       "       [0.49902773],\n",
       "       [0.5041179 ],\n",
       "       [0.4841807 ],\n",
       "       [0.50971687],\n",
       "       [0.50661176],\n",
       "       [0.5091064 ],\n",
       "       [0.50498796],\n",
       "       [0.5077384 ],\n",
       "       [0.47962183],\n",
       "       [0.47808966],\n",
       "       [0.4946619 ],\n",
       "       [0.49883622],\n",
       "       [0.52457297],\n",
       "       [0.49626654],\n",
       "       [0.5031105 ],\n",
       "       [0.50217134],\n",
       "       [0.50423783],\n",
       "       [0.49095756],\n",
       "       [0.50218505],\n",
       "       [0.4778745 ],\n",
       "       [0.508418  ],\n",
       "       [0.5072646 ],\n",
       "       [0.47789663],\n",
       "       [0.49208763],\n",
       "       [0.5015648 ],\n",
       "       [0.53042334],\n",
       "       [0.47953936],\n",
       "       [0.50216997],\n",
       "       [0.5114024 ],\n",
       "       [0.4928827 ],\n",
       "       [0.5072855 ],\n",
       "       [0.4944085 ],\n",
       "       [0.4777651 ],\n",
       "       [0.5245364 ],\n",
       "       [0.49231848],\n",
       "       [0.48224357],\n",
       "       [0.4908517 ],\n",
       "       [0.4947938 ],\n",
       "       [0.50455546],\n",
       "       [0.48594117],\n",
       "       [0.48233354],\n",
       "       [0.4951989 ],\n",
       "       [0.52533656],\n",
       "       [0.49468595],\n",
       "       [0.49899125],\n",
       "       [0.49238837],\n",
       "       [0.48886433],\n",
       "       [0.4926429 ],\n",
       "       [0.5056792 ],\n",
       "       [0.50794995],\n",
       "       [0.52556634],\n",
       "       [0.4822129 ],\n",
       "       [0.51393294],\n",
       "       [0.5092208 ],\n",
       "       [0.50512975],\n",
       "       [0.49407923],\n",
       "       [0.5094197 ],\n",
       "       [0.5144073 ],\n",
       "       [0.4914423 ],\n",
       "       [0.5401952 ],\n",
       "       [0.5147196 ],\n",
       "       [0.49064913],\n",
       "       [0.5043829 ],\n",
       "       [0.5240424 ],\n",
       "       [0.52144617],\n",
       "       [0.5272586 ],\n",
       "       [0.487422  ],\n",
       "       [0.494965  ],\n",
       "       [0.4881486 ],\n",
       "       [0.48646048],\n",
       "       [0.49906638],\n",
       "       [0.50715417],\n",
       "       [0.4921949 ],\n",
       "       [0.4898857 ],\n",
       "       [0.518066  ],\n",
       "       [0.5222621 ],\n",
       "       [0.53749835],\n",
       "       [0.4980909 ],\n",
       "       [0.4887858 ],\n",
       "       [0.48441854],\n",
       "       [0.50470513],\n",
       "       [0.5181541 ],\n",
       "       [0.4835568 ],\n",
       "       [0.48271108],\n",
       "       [0.48409942],\n",
       "       [0.47586486],\n",
       "       [0.4883166 ],\n",
       "       [0.48868334],\n",
       "       [0.50088644],\n",
       "       [0.49145487],\n",
       "       [0.530647  ],\n",
       "       [0.5028951 ],\n",
       "       [0.48212123],\n",
       "       [0.48934764],\n",
       "       [0.48827216],\n",
       "       [0.5227417 ],\n",
       "       [0.5094724 ],\n",
       "       [0.509923  ],\n",
       "       [0.49964535],\n",
       "       [0.49593535],\n",
       "       [0.49346954],\n",
       "       [0.4874619 ],\n",
       "       [0.48554474],\n",
       "       [0.50198215],\n",
       "       [0.50218767],\n",
       "       [0.49191564],\n",
       "       [0.49234608],\n",
       "       [0.51155066],\n",
       "       [0.50750256],\n",
       "       [0.47586486],\n",
       "       [0.506953  ],\n",
       "       [0.47725603],\n",
       "       [0.5270556 ],\n",
       "       [0.47586486],\n",
       "       [0.48935053],\n",
       "       [0.49479336],\n",
       "       [0.5191656 ],\n",
       "       [0.5423253 ],\n",
       "       [0.50348336],\n",
       "       [0.5034526 ],\n",
       "       [0.52440274],\n",
       "       [0.49570793],\n",
       "       [0.52214044],\n",
       "       [0.5014143 ],\n",
       "       [0.51012284],\n",
       "       [0.50868994],\n",
       "       [0.4968393 ],\n",
       "       [0.52300745],\n",
       "       [0.5181105 ],\n",
       "       [0.5128449 ],\n",
       "       [0.48717615],\n",
       "       [0.5160848 ],\n",
       "       [0.51227635],\n",
       "       [0.5284156 ],\n",
       "       [0.5012983 ],\n",
       "       [0.501365  ],\n",
       "       [0.49548838],\n",
       "       [0.5217476 ],\n",
       "       [0.511834  ],\n",
       "       [0.49803287],\n",
       "       [0.4862693 ],\n",
       "       [0.48302993],\n",
       "       [0.4830253 ],\n",
       "       [0.5153571 ],\n",
       "       [0.4839345 ],\n",
       "       [0.50024146],\n",
       "       [0.49716875],\n",
       "       [0.48107627],\n",
       "       [0.5026565 ],\n",
       "       [0.512262  ],\n",
       "       [0.50328916],\n",
       "       [0.5103301 ],\n",
       "       [0.52514476],\n",
       "       [0.48800653],\n",
       "       [0.4829202 ],\n",
       "       [0.493857  ],\n",
       "       [0.50060695],\n",
       "       [0.5000252 ],\n",
       "       [0.5245953 ],\n",
       "       [0.49830565],\n",
       "       [0.47704652],\n",
       "       [0.51620173],\n",
       "       [0.49921888],\n",
       "       [0.51339215],\n",
       "       [0.523418  ],\n",
       "       [0.4892145 ],\n",
       "       [0.48603353],\n",
       "       [0.50557685],\n",
       "       [0.50741124],\n",
       "       [0.5221365 ],\n",
       "       [0.48749462],\n",
       "       [0.50734425],\n",
       "       [0.49367377],\n",
       "       [0.5111011 ],\n",
       "       [0.49531883],\n",
       "       [0.5014353 ],\n",
       "       [0.5083462 ],\n",
       "       [0.5052461 ],\n",
       "       [0.5141891 ],\n",
       "       [0.5244532 ],\n",
       "       [0.5383831 ],\n",
       "       [0.49328706],\n",
       "       [0.525471  ],\n",
       "       [0.51587653],\n",
       "       [0.53538024],\n",
       "       [0.495305  ],\n",
       "       [0.5109414 ],\n",
       "       [0.5053411 ],\n",
       "       [0.48732007],\n",
       "       [0.47772202],\n",
       "       [0.48858273],\n",
       "       [0.5155954 ],\n",
       "       [0.5071075 ],\n",
       "       [0.48250225],\n",
       "       [0.5201622 ],\n",
       "       [0.48735058],\n",
       "       [0.4919039 ],\n",
       "       [0.4874325 ],\n",
       "       [0.49331948],\n",
       "       [0.49943793],\n",
       "       [0.48293537],\n",
       "       [0.49452254],\n",
       "       [0.4899838 ],\n",
       "       [0.49330756],\n",
       "       [0.5017673 ],\n",
       "       [0.525834  ],\n",
       "       [0.49839145],\n",
       "       [0.48964795],\n",
       "       [0.5152828 ],\n",
       "       [0.5010783 ],\n",
       "       [0.4960553 ],\n",
       "       [0.49657217],\n",
       "       [0.47790864],\n",
       "       [0.48899215],\n",
       "       [0.4919801 ],\n",
       "       [0.47989932],\n",
       "       [0.5266207 ],\n",
       "       [0.49221417],\n",
       "       [0.47586486],\n",
       "       [0.49531737],\n",
       "       [0.49749085],\n",
       "       [0.51855624],\n",
       "       [0.49881262],\n",
       "       [0.49048623],\n",
       "       [0.48164856],\n",
       "       [0.49329656],\n",
       "       [0.52783155],\n",
       "       [0.5080394 ],\n",
       "       [0.4958887 ],\n",
       "       [0.487987  ],\n",
       "       [0.49294588],\n",
       "       [0.5104766 ],\n",
       "       [0.49779344],\n",
       "       [0.499828  ],\n",
       "       [0.5389323 ],\n",
       "       [0.49044213],\n",
       "       [0.4888937 ],\n",
       "       [0.50853103],\n",
       "       [0.53160596],\n",
       "       [0.53447986],\n",
       "       [0.52427715],\n",
       "       [0.48571387],\n",
       "       [0.51697797],\n",
       "       [0.48214462],\n",
       "       [0.51319385],\n",
       "       [0.49506524],\n",
       "       [0.47586486],\n",
       "       [0.48351294],\n",
       "       [0.52121264],\n",
       "       [0.47744507],\n",
       "       [0.48762745],\n",
       "       [0.47586486],\n",
       "       [0.47586486],\n",
       "       [0.49068043],\n",
       "       [0.5048013 ],\n",
       "       [0.4885507 ],\n",
       "       [0.4782875 ],\n",
       "       [0.48999292],\n",
       "       [0.5193683 ],\n",
       "       [0.49286518],\n",
       "       [0.50786203],\n",
       "       [0.4803303 ],\n",
       "       [0.48937926],\n",
       "       [0.48722336],\n",
       "       [0.496003  ],\n",
       "       [0.4946364 ],\n",
       "       [0.48560515],\n",
       "       [0.49600348],\n",
       "       [0.49123853],\n",
       "       [0.502677  ],\n",
       "       [0.48964617],\n",
       "       [0.5305172 ],\n",
       "       [0.50933856],\n",
       "       [0.5318173 ],\n",
       "       [0.49226514],\n",
       "       [0.49227   ],\n",
       "       [0.48419067],\n",
       "       [0.5127688 ],\n",
       "       [0.52687055],\n",
       "       [0.5100599 ],\n",
       "       [0.5119346 ],\n",
       "       [0.51314837],\n",
       "       [0.4973301 ],\n",
       "       [0.5095394 ],\n",
       "       [0.4892623 ],\n",
       "       [0.5044545 ],\n",
       "       [0.50218296],\n",
       "       [0.4823022 ],\n",
       "       [0.48077017],\n",
       "       [0.4807006 ],\n",
       "       [0.49265137],\n",
       "       [0.49411243],\n",
       "       [0.50923336],\n",
       "       [0.49585047],\n",
       "       [0.5146135 ],\n",
       "       [0.510834  ],\n",
       "       [0.48579034],\n",
       "       [0.4933151 ],\n",
       "       [0.47827592],\n",
       "       [0.5344811 ],\n",
       "       [0.49812126],\n",
       "       [0.5146744 ],\n",
       "       [0.5389347 ],\n",
       "       [0.514003  ],\n",
       "       [0.49247447],\n",
       "       [0.509426  ],\n",
       "       [0.49333817],\n",
       "       [0.4834563 ],\n",
       "       [0.51237833],\n",
       "       [0.48937985],\n",
       "       [0.51537853],\n",
       "       [0.53079075],\n",
       "       [0.48462132],\n",
       "       [0.47947195],\n",
       "       [0.480406  ],\n",
       "       [0.49892464],\n",
       "       [0.5139982 ],\n",
       "       [0.5130085 ],\n",
       "       [0.5220361 ],\n",
       "       [0.5146908 ],\n",
       "       [0.51290345],\n",
       "       [0.48713484],\n",
       "       [0.5112445 ],\n",
       "       [0.48039484],\n",
       "       [0.5046443 ],\n",
       "       [0.5035938 ],\n",
       "       [0.509323  ],\n",
       "       [0.52243197],\n",
       "       [0.51761526],\n",
       "       [0.4976548 ],\n",
       "       [0.5176793 ],\n",
       "       [0.4945995 ],\n",
       "       [0.5019686 ],\n",
       "       [0.4876465 ],\n",
       "       [0.49799135],\n",
       "       [0.5156675 ],\n",
       "       [0.48871833],\n",
       "       [0.48180667],\n",
       "       [0.4794481 ],\n",
       "       [0.49962172]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbrU9QE0do6d",
    "outputId": "66386d26-3031-48c2-d2cb-56d7d415cb39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 2s 5ms/step - loss: 0.6978 - accuracy: 0.5110\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.5010\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.4990\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.4810\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.4980\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.4930\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.4960\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.4980\n",
      "16/16 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Getting the data ready\n",
    "# Generate train dummy data for 1000 Students and dummy test for 500\n",
    "#Columns :Age, Hours of Study & Avg Previous test scores\n",
    "np.random.seed(2018)\n",
    "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=10, batch_size=32)\n",
    "\n",
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1joAQSIkbd7",
    "outputId": "48e95d13-181d-4d28-a765-20e8f55e9ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 4s 11ms/step - loss: 0.6936 - accuracy: 0.4867 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 0.6932 - accuracy: 0.5065 - val_loss: 0.6932 - val_accuracy: 0.4985\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6933 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.4995\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 0.6930 - accuracy: 0.5098 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.6927 - accuracy: 0.5190 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.6928 - accuracy: 0.5097 - val_loss: 0.6932 - val_accuracy: 0.4965\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 0.6926 - accuracy: 0.5130 - val_loss: 0.6932 - val_accuracy: 0.5080\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5090 - val_loss: 0.6929 - val_accuracy: 0.5050\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5227 - val_loss: 0.6928 - val_accuracy: 0.5155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb258990a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "# Generate dummy training dataset\n",
    "x_train = np.random.random((6000,10))\n",
    "y_train = np.random.randint(2, size=(6000, 1))\n",
    "\n",
    "# Generate dummy validation dataset\n",
    "x_val = np.random.random((2000,10))\n",
    "y_val = np.random.randint(2, size=(2000, 1))\n",
    "\n",
    "# Generate dummy test dataset\n",
    "x_test = np.random.random((2000,10))\n",
    "y_test = np.random.randint(2, size=(2000, 1))\n",
    "\n",
    "#Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=10,activation = \"relu\")) #Layer 1\n",
    "model.add(Dense(32,activation = \"relu\"))               #Layer 2\n",
    "model.add(Dense(16,activation = \"relu\"))               #Layer 3\n",
    "model.add(Dense(8,activation = \"relu\"))                #Layer 4\n",
    "model.add(Dense(4,activation = \"relu\"))                #Layer 5\n",
    "model.add(Dense(1,activation = \"sigmoid\"))             #Output Layer\n",
    "\n",
    "#Configure the model\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvPz99HQlCN-",
    "outputId": "14b4865a-2c10-4c45-bb48-3b9c06f54a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Make predictions from the trained model\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wDAxwxiOvXjJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#getting my datasets\n",
    "m1 = pd.read_csv(\"train.csv\")\n",
    "m2 = pd.read_csv(\"test.csv\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "FGzrO7bXsy9g",
    "outputId": "ce9f9bcb-533e-4e24-f5cd-7d6d15c102e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-75eeff6e-1493-48b0-956e-8e75b4807152\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>504036</td>\n",
       "      <td>53</td>\n",
       "      <td>42953529.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>241</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30930.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30930</td>\n",
       "      <td>30930</td>\n",
       "      <td>42900000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42900000</td>\n",
       "      <td>42900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1564667</td>\n",
       "      <td>443</td>\n",
       "      <td>3708936.0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1115</td>\n",
       "      <td>13475</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>92.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1252807</td>\n",
       "      <td>80</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>432392</td>\n",
       "      <td>56317</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1217484</td>\n",
       "      <td>4446</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22641</th>\n",
       "      <td>843396</td>\n",
       "      <td>53</td>\n",
       "      <td>802.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>154</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22642</th>\n",
       "      <td>1782255</td>\n",
       "      <td>1247</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22643</th>\n",
       "      <td>741214</td>\n",
       "      <td>80</td>\n",
       "      <td>5223889.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22644</th>\n",
       "      <td>579892</td>\n",
       "      <td>53</td>\n",
       "      <td>24369.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>328</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22645</th>\n",
       "      <td>481520</td>\n",
       "      <td>53</td>\n",
       "      <td>23268.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22646 rows Ã— 80 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75eeff6e-1493-48b0-956e-8e75b4807152')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-75eeff6e-1493-48b0-956e-8e75b4807152 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-75eeff6e-1493-48b0-956e-8e75b4807152');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       Unnamed: 0  Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0          504036                53     42953529.0                  2   \n",
       "1         1564667               443      3708936.0                 12   \n",
       "2         1252807                80         2011.0                  5   \n",
       "3          432392             56317            3.0                  2   \n",
       "4         1217484              4446           42.0                  1   \n",
       "...           ...               ...            ...                ...   \n",
       "22641      843396                53          802.0                  2   \n",
       "22642     1782255              1247           76.0                  2   \n",
       "22643      741214                80      5223889.0                  3   \n",
       "22644      579892                53        24369.0                  2   \n",
       "22645      481520                53        23268.0                  1   \n",
       "\n",
       "       Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                           2                           96   \n",
       "1                          13                         1115   \n",
       "2                           0                           12   \n",
       "3                           0                           12   \n",
       "4                           1                            0   \n",
       "...                       ...                          ...   \n",
       "22641                       2                           98   \n",
       "22642                       2                            4   \n",
       "22643                       1                           12   \n",
       "22644                       2                           72   \n",
       "22645                       1                           50   \n",
       "\n",
       "       Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "0                              241                     49   \n",
       "1                            13475                    442   \n",
       "2                                0                      6   \n",
       "3                                0                      6   \n",
       "4                                6                      0   \n",
       "...                            ...                    ...   \n",
       "22641                          154                     49   \n",
       "22642                           12                      2   \n",
       "22643                            2                      6   \n",
       "22644                          328                     36   \n",
       "22645                           66                     50   \n",
       "\n",
       "       Fwd Packet Length Min  Fwd Packet Length Mean  ...  \\\n",
       "0                         47               48.000000  ...   \n",
       "1                          0               92.916667  ...   \n",
       "2                          0                2.400000  ...   \n",
       "3                          6                6.000000  ...   \n",
       "4                          0                0.000000  ...   \n",
       "...                      ...                     ...  ...   \n",
       "22641                     49               49.000000  ...   \n",
       "22642                      2                2.000000  ...   \n",
       "22643                      0                4.000000  ...   \n",
       "22644                     36               36.000000  ...   \n",
       "22645                     50               50.000000  ...   \n",
       "\n",
       "       min_seg_size_forward  Active Mean  Active Std  Active Max  Active Min  \\\n",
       "0                      20.0      30930.0         0.0       30930       30930   \n",
       "1                      20.0          0.0         0.0           0           0   \n",
       "2                      20.0          0.0         0.0           0           0   \n",
       "3                      20.0          0.0         0.0           0           0   \n",
       "4                      40.0          0.0         0.0           0           0   \n",
       "...                     ...          ...         ...         ...         ...   \n",
       "22641                  32.0          0.0         0.0           0           0   \n",
       "22642                  24.0          0.0         0.0           0           0   \n",
       "22643                  20.0          0.0         0.0           0           0   \n",
       "22644                  20.0          0.0         0.0           0           0   \n",
       "22645                  32.0          0.0         0.0           0           0   \n",
       "\n",
       "        Idle Mean  Idle Std  Idle Max  Idle Min  Label  \n",
       "0      42900000.0       0.0  42900000  42900000      0  \n",
       "1             0.0       0.0         0         0      0  \n",
       "2             0.0       0.0         0         0      4  \n",
       "3             0.0       0.0         0         0      0  \n",
       "4             0.0       0.0         0         0     10  \n",
       "...           ...       ...       ...       ...    ...  \n",
       "22641         0.0       0.0         0         0      0  \n",
       "22642         0.0       0.0         0         0      0  \n",
       "22643         0.0       0.0         0         0      0  \n",
       "22644         0.0       0.0         0         0      0  \n",
       "22645         0.0       0.0         0         0      0  \n",
       "\n",
       "[22646 rows x 80 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "v4qZyhEjs1tD",
    "outputId": "31d32c4e-e30a-4a10-c82b-82a3668b40bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-db3c6b53-92b1-4dda-9ee9-a95339a426da\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86401</td>\n",
       "      <td>53</td>\n",
       "      <td>30843.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>63</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232596</td>\n",
       "      <td>443</td>\n",
       "      <td>138235.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>646</td>\n",
       "      <td>1087</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>64.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503421</td>\n",
       "      <td>80</td>\n",
       "      <td>3311889.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494663</td>\n",
       "      <td>443</td>\n",
       "      <td>115894798.0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>801</td>\n",
       "      <td>9882</td>\n",
       "      <td>343</td>\n",
       "      <td>0</td>\n",
       "      <td>38.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37773.08333</td>\n",
       "      <td>2.318754e+04</td>\n",
       "      <td>111402</td>\n",
       "      <td>30964</td>\n",
       "      <td>9620126.5</td>\n",
       "      <td>1.321919e+06</td>\n",
       "      <td>10000000</td>\n",
       "      <td>5422494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122696</td>\n",
       "      <td>443</td>\n",
       "      <td>271039.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>352</td>\n",
       "      <td>3782</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5656</th>\n",
       "      <td>9589</td>\n",
       "      <td>53</td>\n",
       "      <td>48559.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>256</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>493136</td>\n",
       "      <td>53</td>\n",
       "      <td>60580.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>198</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>249633</td>\n",
       "      <td>443</td>\n",
       "      <td>62576429.0</td>\n",
       "      <td>143</td>\n",
       "      <td>214</td>\n",
       "      <td>1778</td>\n",
       "      <td>426531</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>12.433566</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>851309.20000</td>\n",
       "      <td>1.578558e+06</td>\n",
       "      <td>3675120</td>\n",
       "      <td>145180</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.204423e+04</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>198231</td>\n",
       "      <td>53</td>\n",
       "      <td>271760.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>252</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>213529</td>\n",
       "      <td>687</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5661 rows Ã— 80 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db3c6b53-92b1-4dda-9ee9-a95339a426da')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-db3c6b53-92b1-4dda-9ee9-a95339a426da button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-db3c6b53-92b1-4dda-9ee9-a95339a426da');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Unnamed: 0  Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0          86401                53        30843.0                  1   \n",
       "1         232596               443       138235.0                 10   \n",
       "2         503421                80      3311889.0                  4   \n",
       "3         494663               443    115894798.0                 21   \n",
       "4         122696               443       271039.0                  6   \n",
       "...          ...               ...            ...                ...   \n",
       "5656        9589                53        48559.0                  2   \n",
       "5657      493136                53        60580.0                  2   \n",
       "5658      249633               443     62576429.0                143   \n",
       "5659      198231                53       271760.0                  2   \n",
       "5660      213529               687           48.0                  2   \n",
       "\n",
       "      Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                          1                           47   \n",
       "1                          5                          646   \n",
       "2                          0                           24   \n",
       "3                         21                          801   \n",
       "4                          6                          352   \n",
       "...                      ...                          ...   \n",
       "5656                       2                           94   \n",
       "5657                       2                           86   \n",
       "5658                     214                         1778   \n",
       "5659                       2                           68   \n",
       "5660                       0                            4   \n",
       "\n",
       "      Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "0                              63                     47   \n",
       "1                            1087                    405   \n",
       "2                               0                      6   \n",
       "3                            9882                    343   \n",
       "4                            3782                    208   \n",
       "...                           ...                    ...   \n",
       "5656                          256                     47   \n",
       "5657                          198                     43   \n",
       "5658                       426531                    601   \n",
       "5659                          252                     34   \n",
       "5660                            0                      2   \n",
       "\n",
       "      Fwd Packet Length Min  Fwd Packet Length Mean  ...  \\\n",
       "0                        47               47.000000  ...   \n",
       "1                         0               64.600000  ...   \n",
       "2                         6                6.000000  ...   \n",
       "3                         0               38.142857  ...   \n",
       "4                         0               58.666667  ...   \n",
       "...                     ...                     ...  ...   \n",
       "5656                     47               47.000000  ...   \n",
       "5657                     43               43.000000  ...   \n",
       "5658                      0               12.433566  ...   \n",
       "5659                     34               34.000000  ...   \n",
       "5660                      2                2.000000  ...   \n",
       "\n",
       "      min_seg_size_forward   Active Mean    Active Std  Active Max  \\\n",
       "0                     20.0       0.00000  0.000000e+00           0   \n",
       "1                     32.0       0.00000  0.000000e+00           0   \n",
       "2                     20.0       0.00000  0.000000e+00           0   \n",
       "3                     20.0   37773.08333  2.318754e+04      111402   \n",
       "4                     20.0       0.00000  0.000000e+00           0   \n",
       "...                    ...           ...           ...         ...   \n",
       "5656                  32.0       0.00000  0.000000e+00           0   \n",
       "5657                  32.0       0.00000  0.000000e+00           0   \n",
       "5658                  32.0  851309.20000  1.578558e+06     3675120   \n",
       "5659                  20.0       0.00000  0.000000e+00           0   \n",
       "5660                  24.0       0.00000  0.000000e+00           0   \n",
       "\n",
       "      Active Min   Idle Mean      Idle Std  Idle Max  Idle Min  Label  \n",
       "0              0         0.0  0.000000e+00         0         0      0  \n",
       "1              0         0.0  0.000000e+00         0         0      0  \n",
       "2              0         0.0  0.000000e+00         0         0      2  \n",
       "3          30964   9620126.5  1.321919e+06  10000000   5422494      0  \n",
       "4              0         0.0  0.000000e+00         0         0      0  \n",
       "...          ...         ...           ...       ...       ...    ...  \n",
       "5656           0         0.0  0.000000e+00         0         0      0  \n",
       "5657           0         0.0  0.000000e+00         0         0      0  \n",
       "5658      145180  10000000.0  1.204423e+04  10000000  10000000      0  \n",
       "5659           0         0.0  0.000000e+00         0         0      0  \n",
       "5660           0         0.0  0.000000e+00         0         0      0  \n",
       "\n",
       "[5661 rows x 80 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qlyPTXwHs3eS"
   },
   "outputs": [],
   "source": [
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "x = Sequential()\n",
    "x.add(Dense(5, input_dim=3, activation='relu'))\n",
    "x.add(Dense(4, activation='relu'))\n",
    "x.add(Dense(1, activation='sigmoid'))\n",
    "x.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_E9UgnqDtPMy",
    "outputId": "779abccf-d9f0-4426-d57e-898432b32a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfwLV3Hftazw",
    "outputId": "c581d61c-4fc5-46be-b207-6748827885b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 0.6968 - accuracy: 0.5090\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5070\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5100\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4800\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4800\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.4880\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.4920\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5010\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5070\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb258aec1c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fit(train_data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQBO97-ZthYI",
    "outputId": "4c4d2efe-420d-462f-816d-a27d819bc3bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = x.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eb-e-i6ltmyG",
    "outputId": "b73a6512-3a3c-48ba-8288-a7c3328ad183"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5015724 ],\n",
       "       [0.50778145],\n",
       "       [0.50762445],\n",
       "       [0.5047029 ],\n",
       "       [0.4667505 ],\n",
       "       [0.49287605],\n",
       "       [0.5077648 ],\n",
       "       [0.5077454 ],\n",
       "       [0.5009663 ],\n",
       "       [0.5029069 ],\n",
       "       [0.5032483 ],\n",
       "       [0.49811614],\n",
       "       [0.5038999 ],\n",
       "       [0.48477226],\n",
       "       [0.5048093 ],\n",
       "       [0.49029633],\n",
       "       [0.50281286],\n",
       "       [0.4985313 ],\n",
       "       [0.49754125],\n",
       "       [0.49948838],\n",
       "       [0.5027128 ],\n",
       "       [0.48903972],\n",
       "       [0.49360988],\n",
       "       [0.47797754],\n",
       "       [0.5047218 ],\n",
       "       [0.50440586],\n",
       "       [0.48410967],\n",
       "       [0.50368255],\n",
       "       [0.5045639 ],\n",
       "       [0.46511155],\n",
       "       [0.5050411 ],\n",
       "       [0.490217  ],\n",
       "       [0.48500675],\n",
       "       [0.5026471 ],\n",
       "       [0.48501265],\n",
       "       [0.492489  ],\n",
       "       [0.5015359 ],\n",
       "       [0.48901606],\n",
       "       [0.5077593 ],\n",
       "       [0.49351656],\n",
       "       [0.48559466],\n",
       "       [0.4897473 ],\n",
       "       [0.4877279 ],\n",
       "       [0.498529  ],\n",
       "       [0.49030071],\n",
       "       [0.5033332 ],\n",
       "       [0.5078316 ],\n",
       "       [0.50637937],\n",
       "       [0.50348973],\n",
       "       [0.49727055],\n",
       "       [0.45989743],\n",
       "       [0.49399957],\n",
       "       [0.5071798 ],\n",
       "       [0.50503105],\n",
       "       [0.48026368],\n",
       "       [0.49252853],\n",
       "       [0.5076806 ],\n",
       "       [0.5067786 ],\n",
       "       [0.5050695 ],\n",
       "       [0.5067773 ],\n",
       "       [0.48135477],\n",
       "       [0.49286205],\n",
       "       [0.48246133],\n",
       "       [0.4824959 ],\n",
       "       [0.5031023 ],\n",
       "       [0.49631968],\n",
       "       [0.5075572 ],\n",
       "       [0.4775085 ],\n",
       "       [0.50766456],\n",
       "       [0.5076909 ],\n",
       "       [0.50590193],\n",
       "       [0.507646  ],\n",
       "       [0.5077658 ],\n",
       "       [0.4893327 ],\n",
       "       [0.46735108],\n",
       "       [0.48665485],\n",
       "       [0.5054631 ],\n",
       "       [0.47506937],\n",
       "       [0.5009157 ],\n",
       "       [0.50534046],\n",
       "       [0.49929494],\n",
       "       [0.5033212 ],\n",
       "       [0.4911775 ],\n",
       "       [0.50764817],\n",
       "       [0.4983623 ],\n",
       "       [0.50779027],\n",
       "       [0.4773052 ],\n",
       "       [0.5054389 ],\n",
       "       [0.5038524 ],\n",
       "       [0.4993444 ],\n",
       "       [0.5053906 ],\n",
       "       [0.49894172],\n",
       "       [0.5078018 ],\n",
       "       [0.5034801 ],\n",
       "       [0.4818377 ],\n",
       "       [0.48118547],\n",
       "       [0.5048049 ],\n",
       "       [0.4788638 ],\n",
       "       [0.49804923],\n",
       "       [0.48825622],\n",
       "       [0.5057324 ],\n",
       "       [0.50303423],\n",
       "       [0.49754447],\n",
       "       [0.50459015],\n",
       "       [0.5022461 ],\n",
       "       [0.48542333],\n",
       "       [0.5015839 ],\n",
       "       [0.49869254],\n",
       "       [0.5066434 ],\n",
       "       [0.48113248],\n",
       "       [0.5025808 ],\n",
       "       [0.50625604],\n",
       "       [0.5036064 ],\n",
       "       [0.5048404 ],\n",
       "       [0.5046021 ],\n",
       "       [0.5072495 ],\n",
       "       [0.5076325 ],\n",
       "       [0.49050906],\n",
       "       [0.49489537],\n",
       "       [0.5077388 ],\n",
       "       [0.4861313 ],\n",
       "       [0.4992339 ],\n",
       "       [0.507146  ],\n",
       "       [0.475455  ],\n",
       "       [0.50195587],\n",
       "       [0.5016414 ],\n",
       "       [0.49330348],\n",
       "       [0.4991022 ],\n",
       "       [0.50639176],\n",
       "       [0.4624564 ],\n",
       "       [0.5048807 ],\n",
       "       [0.50777406],\n",
       "       [0.5006948 ],\n",
       "       [0.46944135],\n",
       "       [0.5010263 ],\n",
       "       [0.5012724 ],\n",
       "       [0.5037395 ],\n",
       "       [0.5049086 ],\n",
       "       [0.49725962],\n",
       "       [0.5077609 ],\n",
       "       [0.485385  ],\n",
       "       [0.5044268 ],\n",
       "       [0.50505954],\n",
       "       [0.5058499 ],\n",
       "       [0.47950786],\n",
       "       [0.50763077],\n",
       "       [0.50716335],\n",
       "       [0.50627816],\n",
       "       [0.48864233],\n",
       "       [0.50591534],\n",
       "       [0.5030046 ],\n",
       "       [0.48630035],\n",
       "       [0.49160382],\n",
       "       [0.48851606],\n",
       "       [0.505172  ],\n",
       "       [0.5044288 ],\n",
       "       [0.50685316],\n",
       "       [0.50761044],\n",
       "       [0.4936946 ],\n",
       "       [0.50436527],\n",
       "       [0.50670993],\n",
       "       [0.4979874 ],\n",
       "       [0.49762303],\n",
       "       [0.5021844 ],\n",
       "       [0.507674  ],\n",
       "       [0.49581817],\n",
       "       [0.49624366],\n",
       "       [0.5019061 ],\n",
       "       [0.50496215],\n",
       "       [0.5069677 ],\n",
       "       [0.49828234],\n",
       "       [0.48308066],\n",
       "       [0.48216426],\n",
       "       [0.50141263],\n",
       "       [0.5057128 ],\n",
       "       [0.50217026],\n",
       "       [0.50240046],\n",
       "       [0.50372165],\n",
       "       [0.49279404],\n",
       "       [0.48258448],\n",
       "       [0.48347032],\n",
       "       [0.5003784 ],\n",
       "       [0.5048029 ],\n",
       "       [0.50603145],\n",
       "       [0.49710947],\n",
       "       [0.49294657],\n",
       "       [0.5037385 ],\n",
       "       [0.5016055 ],\n",
       "       [0.50411886],\n",
       "       [0.4890922 ],\n",
       "       [0.5059005 ],\n",
       "       [0.47385326],\n",
       "       [0.48844314],\n",
       "       [0.5020457 ],\n",
       "       [0.50233823],\n",
       "       [0.50100887],\n",
       "       [0.49480996],\n",
       "       [0.5078588 ],\n",
       "       [0.5023903 ],\n",
       "       [0.5024455 ],\n",
       "       [0.4932312 ],\n",
       "       [0.48315412],\n",
       "       [0.48584768],\n",
       "       [0.50370955],\n",
       "       [0.5077695 ],\n",
       "       [0.48893237],\n",
       "       [0.5041005 ],\n",
       "       [0.48027685],\n",
       "       [0.5011052 ],\n",
       "       [0.4854376 ],\n",
       "       [0.48919237],\n",
       "       [0.5057413 ],\n",
       "       [0.4870428 ],\n",
       "       [0.498743  ],\n",
       "       [0.5002449 ],\n",
       "       [0.47653106],\n",
       "       [0.5054271 ],\n",
       "       [0.49399725],\n",
       "       [0.5025891 ],\n",
       "       [0.49338195],\n",
       "       [0.49692175],\n",
       "       [0.4993488 ],\n",
       "       [0.5011739 ],\n",
       "       [0.4951245 ],\n",
       "       [0.5031357 ],\n",
       "       [0.4983911 ],\n",
       "       [0.50582606],\n",
       "       [0.5063743 ],\n",
       "       [0.50775266],\n",
       "       [0.50419027],\n",
       "       [0.4760292 ],\n",
       "       [0.5076639 ],\n",
       "       [0.5042842 ],\n",
       "       [0.49247384],\n",
       "       [0.49946442],\n",
       "       [0.505191  ],\n",
       "       [0.49611667],\n",
       "       [0.5059189 ],\n",
       "       [0.4832344 ],\n",
       "       [0.49680176],\n",
       "       [0.5046382 ],\n",
       "       [0.5023821 ],\n",
       "       [0.48755336],\n",
       "       [0.50469893],\n",
       "       [0.5030022 ],\n",
       "       [0.50166804],\n",
       "       [0.4831197 ],\n",
       "       [0.4836645 ],\n",
       "       [0.45902568],\n",
       "       [0.49096966],\n",
       "       [0.49913922],\n",
       "       [0.500095  ],\n",
       "       [0.5043055 ],\n",
       "       [0.48796865],\n",
       "       [0.49425444],\n",
       "       [0.49499738],\n",
       "       [0.48812762],\n",
       "       [0.49084574],\n",
       "       [0.5076554 ],\n",
       "       [0.48038918],\n",
       "       [0.5051958 ],\n",
       "       [0.5077188 ],\n",
       "       [0.5041317 ],\n",
       "       [0.4775269 ],\n",
       "       [0.5037295 ],\n",
       "       [0.50779766],\n",
       "       [0.47246203],\n",
       "       [0.4851291 ],\n",
       "       [0.4957301 ],\n",
       "       [0.49709395],\n",
       "       [0.50769234],\n",
       "       [0.5059533 ],\n",
       "       [0.4957855 ],\n",
       "       [0.50543725],\n",
       "       [0.49225113],\n",
       "       [0.5021606 ],\n",
       "       [0.49713236],\n",
       "       [0.4976936 ],\n",
       "       [0.50780064],\n",
       "       [0.45840663],\n",
       "       [0.49589977],\n",
       "       [0.49386868],\n",
       "       [0.49883902],\n",
       "       [0.5041984 ],\n",
       "       [0.50725454],\n",
       "       [0.50375825],\n",
       "       [0.5017178 ],\n",
       "       [0.4871173 ],\n",
       "       [0.49672273],\n",
       "       [0.4975559 ],\n",
       "       [0.4930259 ],\n",
       "       [0.50392   ],\n",
       "       [0.5022228 ],\n",
       "       [0.49379444],\n",
       "       [0.50341684],\n",
       "       [0.4989834 ],\n",
       "       [0.47619224],\n",
       "       [0.4891686 ],\n",
       "       [0.50270206],\n",
       "       [0.4977728 ],\n",
       "       [0.48084402],\n",
       "       [0.50507766],\n",
       "       [0.48353156],\n",
       "       [0.50028396],\n",
       "       [0.5064543 ],\n",
       "       [0.49765393],\n",
       "       [0.5076966 ],\n",
       "       [0.47718924],\n",
       "       [0.50767976],\n",
       "       [0.47620055],\n",
       "       [0.5075865 ],\n",
       "       [0.48294556],\n",
       "       [0.50469816],\n",
       "       [0.50331324],\n",
       "       [0.505584  ],\n",
       "       [0.4935543 ],\n",
       "       [0.4946073 ],\n",
       "       [0.5069426 ],\n",
       "       [0.5035714 ],\n",
       "       [0.5050701 ],\n",
       "       [0.5076966 ],\n",
       "       [0.49264142],\n",
       "       [0.50376177],\n",
       "       [0.49921444],\n",
       "       [0.4999238 ],\n",
       "       [0.50063723],\n",
       "       [0.5077048 ],\n",
       "       [0.49761528],\n",
       "       [0.48316437],\n",
       "       [0.47992328],\n",
       "       [0.5077306 ],\n",
       "       [0.4953059 ],\n",
       "       [0.47228345],\n",
       "       [0.4978477 ],\n",
       "       [0.5077626 ],\n",
       "       [0.4867226 ],\n",
       "       [0.4794939 ],\n",
       "       [0.5077246 ],\n",
       "       [0.47367048],\n",
       "       [0.4910752 ],\n",
       "       [0.48862788],\n",
       "       [0.46989453],\n",
       "       [0.5016105 ],\n",
       "       [0.5011312 ],\n",
       "       [0.4885402 ],\n",
       "       [0.50024766],\n",
       "       [0.49569353],\n",
       "       [0.4931905 ],\n",
       "       [0.50766647],\n",
       "       [0.50530136],\n",
       "       [0.5033242 ],\n",
       "       [0.4967112 ],\n",
       "       [0.5072646 ],\n",
       "       [0.506566  ],\n",
       "       [0.5030217 ],\n",
       "       [0.48512718],\n",
       "       [0.47028208],\n",
       "       [0.5056454 ],\n",
       "       [0.5050177 ],\n",
       "       [0.507632  ],\n",
       "       [0.49826926],\n",
       "       [0.48216256],\n",
       "       [0.483796  ],\n",
       "       [0.5011333 ],\n",
       "       [0.5038742 ],\n",
       "       [0.47718298],\n",
       "       [0.47129798],\n",
       "       [0.48753917],\n",
       "       [0.5026295 ],\n",
       "       [0.5075545 ],\n",
       "       [0.46200347],\n",
       "       [0.47328845],\n",
       "       [0.5064462 ],\n",
       "       [0.5026051 ],\n",
       "       [0.4927679 ],\n",
       "       [0.5077919 ],\n",
       "       [0.48575872],\n",
       "       [0.5077014 ],\n",
       "       [0.506152  ],\n",
       "       [0.4771493 ],\n",
       "       [0.50769174],\n",
       "       [0.5038589 ],\n",
       "       [0.5025168 ],\n",
       "       [0.50637424],\n",
       "       [0.5041677 ],\n",
       "       [0.47769326],\n",
       "       [0.48655513],\n",
       "       [0.5056844 ],\n",
       "       [0.5017664 ],\n",
       "       [0.50552845],\n",
       "       [0.5013389 ],\n",
       "       [0.4806396 ],\n",
       "       [0.503517  ],\n",
       "       [0.50687057],\n",
       "       [0.4882979 ],\n",
       "       [0.49172992],\n",
       "       [0.49625766],\n",
       "       [0.50642455],\n",
       "       [0.5026095 ],\n",
       "       [0.48353598],\n",
       "       [0.49941498],\n",
       "       [0.5077003 ],\n",
       "       [0.4905935 ],\n",
       "       [0.5028089 ],\n",
       "       [0.4905281 ],\n",
       "       [0.5076366 ],\n",
       "       [0.5076824 ],\n",
       "       [0.4746109 ],\n",
       "       [0.48725387],\n",
       "       [0.49437407],\n",
       "       [0.50494355],\n",
       "       [0.4899201 ],\n",
       "       [0.5055569 ],\n",
       "       [0.49433205],\n",
       "       [0.50182796],\n",
       "       [0.5077053 ],\n",
       "       [0.4955618 ],\n",
       "       [0.5033435 ],\n",
       "       [0.5040357 ],\n",
       "       [0.50525284],\n",
       "       [0.5043133 ],\n",
       "       [0.49310914],\n",
       "       [0.5021168 ],\n",
       "       [0.49994308],\n",
       "       [0.5053992 ],\n",
       "       [0.50605565],\n",
       "       [0.47902274],\n",
       "       [0.50653195],\n",
       "       [0.50747615],\n",
       "       [0.50492424],\n",
       "       [0.5033016 ],\n",
       "       [0.48061913],\n",
       "       [0.49039912],\n",
       "       [0.49851283],\n",
       "       [0.5076384 ],\n",
       "       [0.4892509 ],\n",
       "       [0.50472605],\n",
       "       [0.5035179 ],\n",
       "       [0.488017  ],\n",
       "       [0.5062373 ],\n",
       "       [0.50061226],\n",
       "       [0.5064905 ],\n",
       "       [0.5076592 ],\n",
       "       [0.49552804],\n",
       "       [0.50279635],\n",
       "       [0.48596132],\n",
       "       [0.5015867 ],\n",
       "       [0.50419295],\n",
       "       [0.5074498 ],\n",
       "       [0.48646986],\n",
       "       [0.485464  ],\n",
       "       [0.4991345 ],\n",
       "       [0.50686854],\n",
       "       [0.50770974],\n",
       "       [0.4853154 ],\n",
       "       [0.47574538],\n",
       "       [0.5068055 ],\n",
       "       [0.5050878 ],\n",
       "       [0.48079583],\n",
       "       [0.49647942],\n",
       "       [0.5046406 ],\n",
       "       [0.50156015],\n",
       "       [0.48839846],\n",
       "       [0.49773505],\n",
       "       [0.50759596],\n",
       "       [0.50758845],\n",
       "       [0.4764492 ],\n",
       "       [0.49895054],\n",
       "       [0.5038259 ],\n",
       "       [0.50213337],\n",
       "       [0.50497156],\n",
       "       [0.4968929 ],\n",
       "       [0.4895435 ],\n",
       "       [0.5049209 ],\n",
       "       [0.5061951 ],\n",
       "       [0.49445522],\n",
       "       [0.50253123],\n",
       "       [0.5057333 ],\n",
       "       [0.50177544],\n",
       "       [0.4704611 ],\n",
       "       [0.5003703 ],\n",
       "       [0.5032127 ],\n",
       "       [0.5076958 ],\n",
       "       [0.48947942],\n",
       "       [0.50427175],\n",
       "       [0.46847486],\n",
       "       [0.5073848 ],\n",
       "       [0.48752147],\n",
       "       [0.49798384],\n",
       "       [0.4675321 ],\n",
       "       [0.500498  ],\n",
       "       [0.47789663],\n",
       "       [0.5054599 ],\n",
       "       [0.5031505 ],\n",
       "       [0.5057023 ],\n",
       "       [0.50045365],\n",
       "       [0.5077338 ],\n",
       "       [0.4925865 ],\n",
       "       [0.50766903],\n",
       "       [0.50252783]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfpT6JbBtm-s",
    "outputId": "d280bf6c-e0ff-43f8-d5fd-2f9f393d1fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.6936 - accuracy: 0.4930\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5030\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5180\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4980\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5040\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5030\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5010\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5040\n",
      "16/16 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Getting the data ready\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#getting my datasets\n",
    "m1 = pd.read_csv(\"train.csv\")\n",
    "m2 = pd.read_csv(\"test.csv\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "x = Sequential()\n",
    "x.add(Dense(5, input_dim=3, activation='relu'))\n",
    "x.add(Dense(4, activation='relu'))\n",
    "x.add(Dense(1, activation='sigmoid'))\n",
    "x.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train the model and make predictions\n",
    "x.fit(train_data, labels, epochs=10, batch_size=32)\n",
    "\n",
    "#Make predictions from the trained model\n",
    "pred = x.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klqa6sxfuW5e",
    "outputId": "4e490c2d-a5d0-422f-c821-f6b404572ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [ 0  1  2  3  4  5  6  7 10 11 12 14]\n"
     ]
    }
   ],
   "source": [
    "target=m1[\"Label\"]\n",
    "print('Class labels:', np.unique(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JKXyVr0MQk7N"
   },
   "outputs": [],
   "source": [
    "target=m1[\"Label\"]\n",
    "target1=X_train[\"Label\"]\n",
    "target2=X_val[\"Label\"]\n",
    "target3=X_test[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9bhJDwaulUo",
    "outputId": "df177ab0-6513-4836-d398-32cba9beaf4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "213/213 [==============================] - 2s 5ms/step - loss: -9145195520.0000 - accuracy: 5.1520e-04 - val_loss: -67841794048.0000 - val_accuracy: 0.0015\n",
      "Epoch 2/10\n",
      "213/213 [==============================] - 1s 5ms/step - loss: -1938826330112.0000 - accuracy: 5.1520e-04 - val_loss: -7210684907520.0000 - val_accuracy: 0.0015\n",
      "Epoch 3/10\n",
      "213/213 [==============================] - 1s 4ms/step - loss: -37786950303744.0000 - accuracy: 5.1520e-04 - val_loss: -93778178211840.0000 - val_accuracy: 0.0015\n",
      "Epoch 4/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: -279316185219072.0000 - accuracy: 5.1520e-04 - val_loss: -553742181072896.0000 - val_accuracy: 0.0015\n",
      "Epoch 5/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: -1271417022709760.0000 - accuracy: 5.1520e-04 - val_loss: -2144632729239552.0000 - val_accuracy: 0.0015\n",
      "Epoch 6/10\n",
      "213/213 [==============================] - 1s 4ms/step - loss: -4073292491128832.0000 - accuracy: 5.1520e-04 - val_loss: -6188226461040640.0000 - val_accuracy: 0.0015\n",
      "Epoch 7/10\n",
      "213/213 [==============================] - 1s 4ms/step - loss: -10280570084917248.0000 - accuracy: 5.1520e-04 - val_loss: -14524731139031040.0000 - val_accuracy: 0.0015\n",
      "Epoch 8/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: -22517482740776960.0000 - accuracy: 5.1520e-04 - val_loss: -30177926280380416.0000 - val_accuracy: 0.0015\n",
      "Epoch 9/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: -43992237616398336.0000 - accuracy: 5.1520e-04 - val_loss: -56275994406813696.0000 - val_accuracy: 0.0015\n",
      "Epoch 10/10\n",
      "213/213 [==============================] - 1s 3ms/step - loss: -78442904737021952.0000 - accuracy: 5.1520e-04 - val_loss: -97662471069761536.0000 - val_accuracy: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb240d4aaf0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "X_train = m1.sample(frac = 0.5)\n",
    "y_train = target1\n",
    "\n",
    "# Generate dummy validation dataset\n",
    "X_val = m1.sample(frac = 0.3)\n",
    "y_val = target2\n",
    "\n",
    "# Generate dummy test dataset\n",
    "X_test = m1.sample(frac = 0.2)\n",
    "y_test = target3\n",
    "#Define the model architecture\n",
    "a = Sequential()\n",
    "a.add(Dense(64, input_dim=80,activation = \"relu\")) #Layer 1\n",
    "a.add(Dense(32,activation = \"relu\"))               #Layer 2\n",
    "a.add(Dense(16,activation = \"relu\"))               #Layer 3\n",
    "a.add(Dense(8,activation = \"relu\"))                #Layer 4\n",
    "a.add(Dense(4,activation = \"relu\"))                #Layer 5\n",
    "a.add(Dense(1,activation = \"sigmoid\"))             #Output Layer\n",
    "\n",
    "#Configure the model\n",
    "a.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "a.fit(X_train, y_train, batch_size=64, epochs=10, validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSMR30X65uq3",
    "outputId": "6d403969-f622-458c-a892-8ef119a0257b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=a.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "55ogNs8xPFnD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "lIqsw5i_PP-Y",
    "outputId": "c7419bce-1342-40b7-f4ca-0fe882ba081e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-597a35cca4be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=predictions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
